{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2574068,"sourceType":"datasetVersion","datasetId":1562973},{"sourceId":4803640,"sourceType":"datasetVersion","datasetId":2781321},{"sourceId":8538683,"sourceType":"datasetVersion","datasetId":5082145}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = 256\nBATCH_SIZE = 32\nCHANNELS = 3","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"Dataset\", shuffle=True, image_size  = (IMAGE_SIZE, IMAGE_SIZE), batch_size = BATCH_SIZE)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classname = dataset.class_names\nclassname","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h>Visualize some of the images from out dataset<h>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor image_batch, label_batch in dataset.take(1):\n    for i in range(12):\n        ax = plt.subplot(3,4, i+1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(classname[labels_batch[i]])\n        plt.axis(\"off\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><h>Split the dataset<h><b>\n1. Training\n2. Validation\n3. Testing","metadata":{}},{"cell_type":"code","source":"len(dataset)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = 0.8\nlen(dataset)*train_size","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = dataset.take(54)\nlen(train_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds = dataset.skip(54)\nlen(test_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_size = 0.1\nlen(dataset) * val_size","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_ds = test_ds.take(6)\nlen(val_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds = test_ds.skip(6)\nlen(test_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_split=0.8\nval_split=0.1\ntest_split=0.1\n\nassert train_split + val_split + test_split == 1","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_dataset_paratitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    assert train_split + val_split + test_split == 1\n    \n    ds_size = len(ds)\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n    train_size = int(train_split*ds_size)\n    val_size = int(val_split*ds_size)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds, val_ds, test_ds = get_dataset_paratitions_tf(dataset)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(val_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(test_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cache, Shuffle, and Prefetch the dataset","metadata":{}},{"cell_type":"code","source":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Resizing & Normalization","metadata":{}},{"cell_type":"code","source":"resize_and_rescale = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE), \n    layers.experimental.preprocessing.Rescaling(1.0/255)\n])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmenation  = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2)\n])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = train_ds.map(\nlambda x, y : (data_augmenation(x, training=True), y)).prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model Arc...","metadata":{}},{"cell_type":"code","source":"input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\nn_classes = 3\n\nmodel = models.Sequential([\n    resize_and_rescale,\n    layers.Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = input_shape),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Flatten(), \n    \n    layers.Dense(64, activation='relu'),\n    \n    layers.Dense(n_classes, activation='softmax'),\n    \n])\n\nmodel.build(input_shape=input_shape)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer = 'adam', \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n    metrics = ['accuracy'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs = 10, \n    batch_size = BATCH_SIZE, \n    verbose = 1,\n    validation_data = val_ds\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores = model.evaluate(test_ds)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history.params","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history.history.keys()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(history.history['loss'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(history.history['loss'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc  = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_acc","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualize Loss & Accuarcy in Graph","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nplt.plot(range(10), acc, label = \"Training Accuracy\")\nplt.plot(range(10), val_acc, label = \"Validation Accuracy\")\nplt.legend(loc = 'lower right')\nplt.title('Training & Validation Accuarcy')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(10), loss, label = \"Training Loss\")\nplt.plot(range(10), val_loss, label = \"Validation Loss\")\nplt.legend(loc = 'upper right')\nplt.title('Training & Validation Loss')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfor image_batch , labels_batch in test_ds.take(1):\n    first_img = image_batch[0].numpy().astype('uint8')\n    first_label = labels_batch[0].numpy()\n    \n    print(\"first image to predict\")\n    plt.imshow(first_img)\n    print('actual label:', classname[first_label])\n    \n    batch_prediction = model.predict(image_batch)\n    print('predicted label:', classname[np.argmax(batch_prediction[0])])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Homework to build a flask application for potato disease classification\nand give ss on our discord server","metadata":{}},{"cell_type":"code","source":"def predict(model, img):\n    img_array = tf.keras.preprocessing.image.img_to_array(img.numpy())\n    img_array = tf.expand_dims(img_array, 0)\n    \n    prediction = model.predict(img_array)\n    \n    predicted_class = classname[np.argmax(prediction[0])]\n    confidence = round(100 * (np.argmax(prediction[0])), 2)\n    return predicted_class, confidence","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize = (15,15))\n\nfor images,labels in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3 ,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        predicted_class, confidence = predict(model, images[i])\n        actual_class = classname[labels[i]]\n        \n        plt.title(f\"Actual :{actual_class}, \\n Predicted: {predicted_class}. \\n Confidence: {confidence}%\")\n        \n        plt.axis(\"off\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}